<!-- Generated by SpecStory -->

# Ollama Container Startup Issue (2025-04-28 09:52:42)

_**User**_

runninng `just start` will start all containers except ollama where it just repeatedly echos "Waiting for Ollama to be ready..."

What would be the issue causing this and how can I fix it?

---

_**Assistant**_



---

Okay, let's figure out why Ollama isn't becoming ready. The "Waiting for Ollama to be ready..." message comes from the `start-services.sh` script, which performs health checks before proceeding. This indicates the script can't successfully connect to the Ollama service at its expected endpoint.

Here are the most likely reasons and how we can investigate:

1.  **Ollama Container Startup Failure:** The Ollama service itself might be crashing or failing to initialize properly within its container. This could be due to configuration errors, resource issues, or problems accessing the GPU.
2.  **GPU Configuration Problem:** Even if `nvidia-smi` works on the host (as checked by `just check-gpu`), Docker might not be configured correctly to pass the GPU through to the `ollama` container.
3.  **Network Issues:** Although less likely if other services start, there might be a problem with the `ai-network` preventing the health check from reaching `ollama:11434`.
4.  **Incorrect Health Check:** The command used in `start-services.sh` to check Ollama's health might be wrong (e.g., incorrect URL, port, or command syntax).

**To diagnose this, let's start by looking at:**

1.  **Ollama's Logs:** This will tell us directly if the Ollama service is encountering errors.
2.  **The Health Check Script:** To see *how* the script determines if Ollama is ready.
3.  **The Docker Compose File:** To verify Ollama's service definition, especially network and GPU settings.

Could you please provide the contents of `start-services.sh` and `docker-compose.yml`?

Also, please run the following command in your terminal and share the output:

```bash
just logs-service ollama
```

This will show us the real-time logs from the Ollama container, which should give us the clearest indication of the problem.

---

_**User**_

this is the log output from the above command:

ollama  | 2025/04/28 02:55:37 routes.go:1232: INFO server config env="map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:2048 OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
ollama  | time=2025-04-28T02:55:37.966Z level=INFO source=images.go:458 msg="total blobs: 0"
ollama  | time=2025-04-28T02:55:37.966Z level=INFO source=images.go:465 msg="total unused blobs removed: 0"
ollama  | time=2025-04-28T02:55:37.966Z level=INFO source=routes.go:1299 msg="Listening on [::]:11434 (version 0.6.6)"
ollama  | time=2025-04-28T02:55:37.966Z level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
ollama  | time=2025-04-28T02:55:38.182Z level=INFO source=types.go:130 msg="inference compute" id=GPU-75475875-dd58-d07d-464d-5663d0792e29 library=cuda variant=v12 compute=8.6 driver=12.8 name="NVIDIA GeForce RTX 3060 Laptop GPU" total="5.7 GiB" available="5.2 GiB"

Is there anything there that indicates a problem?

---

_**Assistant**_



---

Based on the logs you provided, **Ollama appears to be starting correctly and successfully detecting your NVIDIA GPU.**

Here's the breakdown:

1.  `Listening on [::]:11434`: This confirms the Ollama server started and is listening for connections on port 11434 within its container.
2.  `looking for compatible GPUs`: It initiates the GPU detection process.
3.  `inference compute ... library=cuda ... name="NVIDIA GeForce RTX 3060 Laptop GPU"`: This shows it found your GPU, identified it correctly, and successfully initialized it using CUDA. It even reports the available memory.

Since the Ollama service itself seems healthy and has GPU access, the problem is almost certainly in how the `start-services.sh` script is trying to *check* if Ollama is ready. The health check mechanism within that script is likely failing, even though Ollama is running fine.

To fix this, we need to see the health check logic.

Could you please show me the contents of `start-services.sh` and `docker-compose.yml`? This will let us see how the check is performed and verify the network setup.

---

_**User**_

line 19 of @start-services.sh is where the ollama container is started (I think)

---

_**Assistant**_



---

You've found the exact line causing the issue!

```bash
# Line 19
until docker-compose exec -T ollama curl -s --fail http://localhost:11434/api/tags > /dev/null 2>&1; do
```

The problem is with `http://localhost:11434`. When you run `docker-compose exec -T ollama ...`, the `curl` command is executed *inside* the `ollama` container. Within that container, `localhost` refers to the container itself. While Ollama *is* running on port 11434 inside its own container, this check isn't verifying reachability *across* the Docker network from other potential clients (like the health check script or the `open-webui` service).

According to the Docker Compose rules (`services-dependencies` and `monitoring-setup.mdc`), services should communicate using their service names over the shared `ai-network`. The Ollama service should be reachable at `http://ollama:11434` from other containers on that network.

The fix is to change `localhost` to `ollama` in the `curl` command for the health check. The same logic applies to the Open WebUI and Uptime Kuma health checks – they should use their service names (`open-webui`, `uptime-kuma`) instead of `localhost` if the check is executed from *within* another container (though in this script, the `exec` targets the service being checked, so `localhost` *might* work for them, but using the service name is more robust and consistent).

Let's correct line 19 in `start-services.sh`. I'll also proactively correct the Open WebUI and Uptime Kuma checks for consistency, assuming their service names are `open-webui` and `uptime-kuma` respectively, and that Uptime Kuma listens on port `3000` internally as per the standard image (even though it's exposed on `3001`).



---

```diff
  # Wait for Ollama to be ready
  echo "Checking Ollama health..."
- until docker-compose exec -T ollama curl -s --fail http://localhost:11434/api/tags > /dev/null 2>&1; do
+ until docker-compose exec -T ollama curl -s --fail http://ollama:11434/api/tags > /dev/null 2>&1; do
      echo "Waiting for Ollama to be ready..."
      sleep 2
```

```diff
  # Wait for Open WebUI to be ready
  echo "Checking Open WebUI health..."
- until docker-compose exec -T open-webui curl -s --fail http://localhost:8080 > /dev/null 2>&1; do
+ until docker-compose exec -T open-webui curl -s --fail http://open-webui:8080 > /dev/null 2>&1; do
      echo "Waiting for Open WebUI to be ready..."
      sleep 2
```

```diff
  # Wait for Uptime Kuma to be ready
  echo "Checking Uptime Kuma health..."
- until docker-compose exec -T uptime-kuma curl -s --fail http://localhost:3000/health > /dev/null 2>&1; do
+ until docker-compose exec -T uptime-kuma curl -s --fail http://uptime-kuma:3000/health > /dev/null 2>&1; do
      echo "Waiting for Uptime Kuma to be ready..."
      sleep 2
```

---

I've updated the health check URLs in `start-services.sh` to use the Docker service names (`ollama`, `open-webui`, `uptime-kuma`) instead of `localhost`. This ensures the checks correctly verify service availability across the Docker network.

Please try running `just start` again. It should now correctly wait for Ollama (and the other services) and proceed once they are reachable.

---

_**User**_

This is the relevant output of `just start`:

tarting services with docker-compose...
[+] Running 4/4
 ✔ Container uptime-kuma                      Removed                                                          0.0s 
 ✔ Container open-webui                       Removed                                                          0.1s 
 ✔ Container ollama                           Removed                                                          0.0s 
 ✔ Network openwui_infrastructure_ai-network  Removed                                                          0.3s 
[+] Running 4/4
 ✔ Network openwui_infrastructure_ai-network  Created                                                          0.1s 
 ✔ Container ollama                           Started                                                          0.4s 
 ✔ Container open-webui                       Started                                                          0.5s 
 ✔ Container uptime-kuma                      Started                                                          0.6s 
Waiting for services to be ready...
Checking Ollama health...
Waiting for Ollama to be ready...
Waiting for Ollama to be ready...
Waiting for Ollama to be ready...
Waiting for Ollama to be ready...
Waiting for Ollama to be ready...
Waiting for Ollama to be ready...

So it looks like the ollama container starts, but why is it still being waited on to be ready? What exactly does this mean?

---

_**Assistant**_



---

Okay, that's unexpected. The containers are definitely starting, but the script is stuck waiting specifically for the Ollama health check to pass.

Let's break down what "Waiting for Ollama to be ready..." means in the context of the `start-services.sh` script:

1.  The script executes `docker-compose up -d`, which successfully starts the `ollama`, `open-webui`, and `uptime-kuma` containers.
2.  It then enters a loop specifically for Ollama:
    ```bash
    until docker-compose exec -T ollama curl -s --fail http://ollama:11434/api/tags > /dev/null 2>&1; do
        echo "Waiting for Ollama to be ready..."
        sleep 2
    done
    ```
3.  This loop repeatedly runs the command `curl -s --fail http://ollama:11434/api/tags` *inside* the running `ollama` container.
4.  The loop continues *until* that `curl` command succeeds. "Success" here means:
    *   It can resolve the hostname `ollama` to an IP address (which should be the `ollama` container's IP on the `ai-network`).
    *   It can establish a connection to that IP on port `11434`.
    *   It receives a valid HTTP response (status code 2xx) from the `/api/tags` endpoint. The `--fail` flag makes `curl` return an error if the HTTP status is not 2xx.
5.  Since the loop isn't exiting, it means the `curl` command executed *inside* the `ollama` container is consistently failing to get a successful response from `http://ollama:11434/api/tags`.

**Possible Reasons for Failure:**

1.  **Network Resolution Failure:** The `ollama` container might not be able to resolve the hostname `ollama` to its own IP address on the Docker network. This would be unusual if they are on the same network, but worth checking.
2.  **`curl` Not Available:** Does the base Ollama Docker image you're using actually include the `curl` command? If not, `docker-compose exec ... curl ...` will fail.
3.  **Internal Service Delay:** Although the container is "Started", maybe the web server *inside* the Ollama service takes a bit longer to become fully active and respond to requests, even from itself via the network address.
4.  **Endpoint Issue:** Is `/api/tags` still the correct basic endpoint? Perhaps it changed in a newer Ollama version or requires something specific? (Though it usually works for a basic check).

**Let's Diagnose Further:**

Run the following command in your terminal *while the script is stuck in the loop* and share the output. This will execute the check manually with verbose output, showing us exactly where it's failing:

```bash
docker-compose exec ollama curl -v http://ollama:11434/api/tags
```

Also, let's quickly check if `curl` is installed:

```bash
docker-compose exec ollama which curl
```

---

_**User**_

It is reason 2. This is the output of trying to run the curl command you gave:

OCI runtime exec failed: exec failed: unable to start container process: exec: "curl": executable file not found in $PATH

What's the best fix for this

---

_**Assistant**_



---

Ah, that explains it perfectly! The `curl` command is not installed in the official Ollama Docker image, so the health check command `docker-compose exec -T ollama curl ...` fails because the executable `curl` cannot be found inside that container.

**Solution:**

Since the goal is to ensure Ollama is reachable *by other services* (like Open WebUI), we can perform the health check *from* a container that *does* have `curl`. Looking at your `start-services.sh` script, it already tries to check Open WebUI using `curl`:

```bash
# Wait for Open WebUI to be ready
echo "Checking Open WebUI health..."
until docker-compose exec -T open-webui curl -s --fail http://open-webui:8080 > /dev/null 2>&1; do
    # ...
done
```

Assuming the `open-webui` image *does* contain `curl` (which is likely), we can modify the Ollama health check to run inside the `open-webui` container instead, checking if *it* can reach `ollama`.

Let's modify line 19 in `start-services.sh` again:



---

Tool edit_file not found. Try switching to Agent mode.

---



---

Apologies, I cannot directly edit the file for you.

However, the fix is straightforward. You need to change the container name in the Ollama health check command from `ollama` to `open-webui`.

Here's how line 19 in `start-services.sh` should look:

```bash:start-services.sh
# ... existing code ...
# Wait for Ollama to be ready
echo "Checking Ollama health..."
# Execute the check from within the open-webui container, as ollama image lacks curl
until docker-compose exec -T open-webui curl -s --fail http://ollama:11434/api/tags > /dev/null 2>&1; do
    echo "Waiting for Ollama to be ready..."
    sleep 2
done
echo "Ollama is ready!"

# Wait for Open WebUI to be ready
# ... rest of the script ...
```

**Change Summary:**

*   The command `docker-compose exec -T ollama ...` was changed to `docker-compose exec -T open-webui ...`.

Please make this change manually in your `start-services.sh` file and try running `just start` again. This should now correctly check Ollama's status by attempting to connect from the Open WebUI container.

---

_**User**_

Now the same thing appears to be happening with the Kuma container:

Starting services with docker-compose...
[+] Running 4/4
 ✔ Container uptime-kuma                      Removed                                                          0.0s 
 ✔ Container open-webui                       Removed                                                          0.1s 
 ✔ Container ollama                           Removed                                                          0.0s 
 ✔ Network openwui_infrastructure_ai-network  Removed                                                          0.3s 
[+] Running 4/4
 ✔ Network openwui_infrastructure_ai-network  Created                                                          0.1s 
 ✔ Container ollama                           Started                                                          0.4s 
 ✔ Container open-webui                       Started                                                          0.4s 
 ✔ Container uptime-kuma                      Started                                                          0.6s 
Waiting for services to be ready...
Checking Ollama health...
Ollama is ready!
Checking Open WebUI health...
Waiting for Open WebUI to be ready...
Waiting for Open WebUI to be ready...
Waiting for Open WebUI to be ready...
Waiting for Open WebUI to be ready...
Waiting for Open WebUI to be ready...
Open WebUI is ready!
Checking Uptime Kuma health...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...
Waiting for Uptime Kuma to be ready...

Would the same solution work here?

---

_**Assistant**_



---

Yes, exactly! It looks like we're encountering the same issue with the Uptime Kuma container.

The script is currently trying to run `curl` *inside* the `uptime-kuma` container:

```bash
# Line 31
until docker-compose exec -T uptime-kuma curl -s --fail http://uptime-kuma:3000/health > /dev/null 2>&1; do
    echo "Waiting for Uptime Kuma to be ready..."
    sleep 2
done
```

It's very likely that the official `louislam/uptime-kuma:1` image, like the Ollama image, doesn't include `curl` by default. Therefore, the `exec` command fails because it can't find the `curl` executable within the `uptime-kuma` container.

**The Solution:**

The same fix should work. We'll run the health check for Uptime Kuma from the `open-webui` container, which we know has `curl`.

Please modify the Uptime Kuma health check in `start-services.sh` like this:

```bash:start-services.sh
# ... existing code ...

# Wait for Uptime Kuma to be ready
echo "Checking Uptime Kuma health..."
# Execute the check from within the open-webui container
until docker-compose exec -T open-webui curl -s --fail http://uptime-kuma:3000/health > /dev/null 2>&1; do
    echo "Waiting for Uptime Kuma to be ready..."
    sleep 2
done
echo "Uptime Kuma is ready!"

# ... rest of the script ...
```

**Change Summary:**

*   On the line starting the Uptime Kuma health check loop, change `docker-compose exec -T uptime-kuma ...` to `docker-compose exec -T open-webui ...`.

Apply this change, and `just start` should hopefully get past all the health checks now.

---

_**User**_

That did not fix the Kuma health check

---

_**Assistant**_



---

Okay, that's puzzling. If running the check from `open-webui` worked for Ollama, it *should* work for Uptime Kuma too, assuming `open-webui` and `uptime-kuma` are on the same network and the Uptime Kuma service is actually healthy and listening internally on port `3000`.

Let's investigate why the check `docker-compose exec -T open-webui curl -s --fail http://uptime-kuma:3000/health` is failing.

Please run the following commands and share their output:

1.  **Manual Verbose Check:** Execute the check manually from the `open-webui` container with verbose output to see exactly what `curl` is doing:
    ```bash
    docker-compose exec open-webui curl -v http://uptime-kuma:3000/health
    ```
    This will show DNS resolution, connection attempts, and the HTTP response (or lack thereof).

2.  **Uptime Kuma Logs:** Check the logs for the Uptime Kuma container to see if it's starting correctly or reporting any errors:
    ```bash
    docker-compose logs uptime-kuma
    ```

3.  **Docker Compose Service Definition:** Please provide the section for the `uptime-kuma` service from your `docker-compose.yml` file. We need to confirm:
    *   It's connected to the `ai-network`.
    *   It's configured to listen internally on port `3000` (the `ports:` section usually maps like `HOST_PORT:CONTAINER_PORT`, e.g., `3001:3000`).

This information should help pinpoint whether it's a network issue, an internal Uptime Kuma problem, or an incorrect health check endpoint/port.

---

_**User**_

Seems to be a hostname resolution failure as you can see in the linked command output. What would cause this?

---

_**Assistant**_



---

That output `Could not resolve host: uptime-kuma` definitively tells us the problem:

When the `curl` command runs inside the `open-webui` container, it tries to look up the IP address associated with the hostname `uptime-kuma`, but Docker's internal DNS system isn't providing one.

This almost always means one of the following:

1.  **`uptime-kuma` is not on the same network as `open-webui`:** Docker Compose networking relies on services being connected to the *same* user-defined network (in your case, `ai-network`) to resolve each other by service name. If `uptime-kuma` wasn't correctly configured to join `ai-network`, other services like `open-webui` won't be able to find it by name.
2.  **The service isn't actually named `uptime-kuma`:** Double-check the service name defined in your `docker-compose.yml`. If the service is defined with a different name (e.g., `kuma`, `monitor`), then `http://uptime-kuma:3000` won't resolve. The hostname used in the URL *must* match the service name in the compose file.

**To confirm which it is, please show me the relevant sections of your `docker-compose.yml` file:**

*   The top-level `networks:` section where `ai-network` is defined.
*   The full service definition for `uptime-kuma`.
*   The full service definition for `open-webui`.

This will let us verify that both services are correctly defined and attached to the `ai-network`.

---

_**User**_

Take a look at the compose file

---

_**Assistant**_



---

Okay, I've reviewed your `docker-compose.yml`.

The configuration looks **correct**:

1.  The `ai-network` is properly defined as a bridge network.
2.  Both the `open-webui` service and the `uptime-kuma` service are correctly configured to use `ai-network`.
3.  The service name is indeed `uptime-kuma`.

Given this setup, the `open-webui` container *should* be able to resolve the hostname `uptime-kuma` using Docker's internal DNS. The fact that it's failing with `Could not resolve host: uptime-kuma` is unusual.

Here are a few possibilities:

1.  **Docker Networking Glitch:** Sometimes, Docker's internal networking or DNS can get into a weird state. A simple restart of the Docker daemon/service might resolve it.
2.  **Timing Issue:** Although `depends_on` controls the startup order, there might be a very slight delay before `uptime-kuma` is fully registered on the `ai-network`'s DNS, and the check in `start-services.sh` runs fractionally too soon after `docker-compose up -d` returns. (Seems less likely since it waits for the other services first).
3.  **Container Network Configuration:** A less common issue could be something specific inside the `open-webui` container interfering with its ability to use Docker's DNS (like a modified `/etc/resolv.conf`), but this is unlikely with standard images.

**Recommendation:**

1.  **Restart Docker:** First, please try restarting your Docker daemon/service completely. On most Linux systems, this is something like `sudo systemctl restart docker` or `sudo service docker restart`. On Docker Desktop, quit and restart the application. After restarting Docker, try `just start` again.

2.  **If Restart Fails:** If restarting Docker doesn't solve it, let's try a direct network test. While the script is stuck waiting for Uptime Kuma, please run this command in your terminal and show me the output:
    ```bash
    docker-compose exec open-webui ping -c 3 uptime-kuma
    ```
    This will tell us if the `open-webui` container can reach `uptime-kuma` at a basic network level using its hostname.

---

_**User**_

I was able to ping uptime-kuma from open-webui container using the hostname

---

_**Assistant**_

The reason the script still hangs on Uptime Kuma is that nothing is actually listening on port 3000 inside the container—even though you can resolve and ping `uptime-kuma`, the HTTP check to `http://uptime-kuma:3000/health` will always time out/ refuse because the app is bound to port 3001 internally.

In your compose you have:

```yaml
  uptime-kuma:
    ports:
      - "3001:3000"
```

but **the official Uptime Kuma image listens on port 3001 inside the container**, so you’ve mapped the host’s 3001 → container’s 3000 (where no server lives). That’s why your curl/wget never gets a 200.

To fix:

1) In `docker-compose.yml`, change the Kuma service to expose port 3001 internally:

```yaml
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    volumes:
      - uptime-kuma-data:/app/data
    ports:
      - "3001:3001"            # ← map host 3001 ➞ container 3001
    depends_on:
      - ollama
      - open-webui
    networks:
      - ai-network
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O - http://localhost:3001/health || exit 1"]
      interval: 1m30s
      timeout: 30s
      retries: 5
      start_period: 30s
    restart: unless-stopped
```

2) In your `start-services.sh` health-check loop for Kuma use port 3001:

```bash
echo "Checking Uptime Kuma health..."
until docker-compose exec -T open-webui \
      curl -s --fail http://uptime-kuma:3001/health \
      > /dev/null 2>&1; do
  echo "Waiting for Uptime Kuma to be ready..."
  sleep 2
done
echo "Uptime Kuma is ready!"
```

Once you correct the port mapping + health-check URL to `:3001`, `just start` should detect Kuma as up and finish the script.

---

_**User**_

Explain what this does exactly, both the curl command and the do keyword

---

_**Assistant**_

Here’s what’s happening in that snippet of your health-check loop:

```bash
# 36:38:start-services.sh
until docker-compose exec -T open-webui \
      curl -s --fail http://uptime-kuma:3001/health \
      > /dev/null 2>&1; do
    echo "Waiting for Uptime Kuma to be ready..."
    sleep 2
done
```

1. The `curl` command:  
   - `docker-compose exec -T open-webui curl …`  
     runs `curl` *inside* the `open-webui` container (the `-T` disables stdin).  
   - `-s` (silent) suppresses the progress meter and messages.  
   - `--fail` makes `curl` return a non-zero exit code on HTTP errors (4xx/5xx) instead of outputting the HTML error page.  
   - `http://uptime-kuma:3001/health` is the URL being probed—the internal health endpoint of Uptime Kuma on port 3001.  
   - `> /dev/null 2>&1` redirects both standard output and standard error to `/dev/null`, so you don’t see any of curl’s output.

   In effect, this `curl` invocation *tests* whether Uptime Kuma is up and serving a 2xx response at `/health`. If it succeeds, `curl` exits with status 0; otherwise it exits non-zero.

2. The `until …; do …; done` loop:  
   - In Bash, `until <command>; do …; done` repeatedly executes the body **as long as** `<command>` exits with a non-zero status (i.e. “fails”).  
   - Once `<command>` succeeds (exit 0), the loop stops and execution continues after `done`.  
   - The semicolon before `do` is just Bash syntax to separate the test command from the loop body when they’re on the same line.

Putting it together:

- The script runs the `curl` check inside `open-webui`.  
- If the check fails, it prints  
  ```
  Waiting for Uptime Kuma to be ready...
  ```  
  sleeps 2 seconds, then retries.  
- The loop keeps going until the health endpoint finally replies with HTTP 200, at which point `curl` exits 0 and the loop ends.

---

